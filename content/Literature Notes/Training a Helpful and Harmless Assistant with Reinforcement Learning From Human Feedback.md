
* Explore more callibration of [[Preference Models]] (figure 9) and how well callibrated PM scores lead to RL models upon receiving a reward robustly matchinig up with the preferences of reviewers.
* Understand rejection sampling
*source: https://arxiv.org/pdf/2204.05862.pdf
reading path*
* The effects of reward misspecification: Mapping and mitigating misaligned models - https://arxiv.org/abs/2201.03544